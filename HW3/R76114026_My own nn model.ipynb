{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cff63b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db3471d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "互動資料:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>880</td>\n",
       "      <td>476</td>\n",
       "      <td>3</td>\n",
       "      <td>880175444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>716</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "      <td>879795543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>276</td>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "      <td>874795795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>882399156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "      <td>879959583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating  timestamp\n",
       "0         196      242       3  881250949\n",
       "1         186      302       3  891717742\n",
       "2          22      377       1  878887116\n",
       "3         244       51       2  880606923\n",
       "4         166      346       1  886397596\n",
       "...       ...      ...     ...        ...\n",
       "99995     880      476       3  880175444\n",
       "99996     716      204       5  879795543\n",
       "99997     276     1090       1  874795795\n",
       "99998      13      225       2  882399156\n",
       "99999      12      203       3  879959583\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#匯入user.movie互動資料\n",
    "rating = pd.read_csv(\"Movielens\\\\user_movie.dat\",sep = \"\\t\",names=[\"userId\",\"movieId\",\"rating\",\"timestamp\"])\n",
    "print(\"互動資料:\")\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07a55124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user互動similarity:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auserId</th>\n",
       "      <th>buserId</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>823</td>\n",
       "      <td>0.340297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>0.328166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>339</td>\n",
       "      <td>0.327473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>297</td>\n",
       "      <td>0.322998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>806</td>\n",
       "      <td>0.318959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47145</th>\n",
       "      <td>943</td>\n",
       "      <td>311</td>\n",
       "      <td>0.292593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47146</th>\n",
       "      <td>943</td>\n",
       "      <td>881</td>\n",
       "      <td>0.292412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47147</th>\n",
       "      <td>943</td>\n",
       "      <td>64</td>\n",
       "      <td>0.291997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47148</th>\n",
       "      <td>943</td>\n",
       "      <td>246</td>\n",
       "      <td>0.291895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47149</th>\n",
       "      <td>943</td>\n",
       "      <td>268</td>\n",
       "      <td>0.291561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       auserId  buserId  similarity\n",
       "0            1      823    0.340297\n",
       "1            1       92    0.328166\n",
       "2            1      339    0.327473\n",
       "3            1      297    0.322998\n",
       "4            1      806    0.318959\n",
       "...        ...      ...         ...\n",
       "47145      943      311    0.292593\n",
       "47146      943      881    0.292412\n",
       "47147      943       64    0.291997\n",
       "47148      943      246    0.291895\n",
       "47149      943      268    0.291561\n",
       "\n",
       "[47150 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "User = pd.read_csv(\"Movielens\\\\user_user(knn).dat\",sep = \"\\t\",names=[\"auserId\",\"buserId\",\"similarity\"])\n",
    "print(\"user互動similarity:\")\n",
    "User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06032e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user互動similarity:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auserId</th>\n",
       "      <th>buserId</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>0.321301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>0.306714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "      <td>0.304458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>742</td>\n",
       "      <td>0.301808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>117</td>\n",
       "      <td>0.287419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82793</th>\n",
       "      <td>1682</td>\n",
       "      <td>80</td>\n",
       "      <td>0.140691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82794</th>\n",
       "      <td>1682</td>\n",
       "      <td>369</td>\n",
       "      <td>0.140691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82795</th>\n",
       "      <td>1682</td>\n",
       "      <td>158</td>\n",
       "      <td>0.139170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82796</th>\n",
       "      <td>1682</td>\n",
       "      <td>741</td>\n",
       "      <td>0.139170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82797</th>\n",
       "      <td>1682</td>\n",
       "      <td>569</td>\n",
       "      <td>0.137694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82798 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       auserId  buserId  similarity\n",
       "0            1      151    0.321301\n",
       "1            1      121    0.306714\n",
       "2            1      222    0.304458\n",
       "3            1      742    0.301808\n",
       "4            1      117    0.287419\n",
       "...        ...      ...         ...\n",
       "82793     1682       80    0.140691\n",
       "82794     1682      369    0.140691\n",
       "82795     1682      158    0.139170\n",
       "82796     1682      741    0.139170\n",
       "82797     1682      569    0.137694\n",
       "\n",
       "[82798 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "User = pd.read_csv(\"Movielens\\\\movie_movie(knn).dat\",sep = \"\\t\",names=[\"auserId\",\"buserId\",\"similarity\"])\n",
    "print(\"user互動similarity:\")\n",
    "User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d58578e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "      <th>1682</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
       "userId                                                               ...   \n",
       "1         5.0   3.0   4.0   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...   \n",
       "2         4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0  ...   \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "5         4.0   3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "939       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   5.0   NaN  ...   \n",
       "940       NaN   NaN   NaN   2.0   NaN   NaN   4.0   5.0   3.0   NaN  ...   \n",
       "941       5.0   NaN   NaN   NaN   NaN   NaN   4.0   NaN   NaN   NaN  ...   \n",
       "942       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "943       NaN   5.0   NaN   NaN   NaN   NaN   NaN   NaN   3.0   NaN  ...   \n",
       "\n",
       "movieId  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
       "userId                                                               \n",
       "1         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "5         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "939       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "940       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "941       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "942       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "943       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[943 rows x 1682 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#建立user-item矩陣\n",
    "user_item = pd.pivot_table(rating,values='rating',columns='movieId',index='userId')\n",
    "user_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc8e1bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 4., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item=user_item.values\n",
    "user_item = np.where(np.isnan(user_item), 0, user_item)\n",
    "user_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712f660f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c27f3678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#分割資料集\n",
    "train_data, test_data = train_test_split(user_item, random_state=None, train_size=0.8)\n",
    "print(\"Train data:\")\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e3f297f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Test data:\")\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cf8357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a17dee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of folds (K) for cross-validation\n",
    "k = 5\n",
    "\n",
    "# Define lists to store the evaluation metrics for each fold\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "\n",
    "# Perform K-fold Cross-Validation\n",
    "kf = KFold(n_splits=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63d99596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 400)               673200    \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 400)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 200)               80200     \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1682)              338082    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,091,482\n",
      "Trainable params: 1,091,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 1s 6ms/step - loss: 0.0308\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0259\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0245\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0235\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0228\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0222\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0219\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0213\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0211\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0206\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0202\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0200\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0199\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0194\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0193\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0191\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0187\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0187\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0181\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0182\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0180\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0177\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0175\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0174\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0171\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0170\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0172\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0172\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0171\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0166\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[[ 4.7022855e-01  3.4013918e-01  1.9715665e-01 ... -3.3497179e-04\n",
      "   2.4888755e-03 -2.0040284e-04]\n",
      " [ 2.9439491e-01 -2.2809692e-03 -9.5350686e-03 ... -1.8189875e-03\n",
      "   6.1993254e-05  1.2972098e-03]\n",
      " [ 7.8716509e-02 -1.3426300e-02 -9.1275759e-04 ...  9.9349869e-05\n",
      "   1.3481256e-03 -7.8313786e-04]\n",
      " ...\n",
      " [ 2.3894325e-02  1.6576899e-02  2.7404386e-03 ...  1.7920678e-04\n",
      "   1.3077599e-03 -6.5817626e-04]\n",
      " [ 3.8902816e-01  5.0381990e-04  1.3059819e-01 ... -1.3104716e-04\n",
      "   8.2830165e-04  5.5926107e-04]\n",
      " [ 4.3284410e-01  3.7540268e-02  7.3376402e-02 ... -1.7775509e-03\n",
      "   3.1804885e-03  3.1929059e-04]]\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_33 (Dense)            (None, 400)               673200    \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 400)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 200)               80200     \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1682)              338082    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,091,482\n",
      "Trainable params: 1,091,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 1s 7ms/step - loss: 0.0304\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0255\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0240\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0232\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0225\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0224\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0217\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0211\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0208\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0203\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0201\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0199\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0197\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0192\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0191\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0189\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0187\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0185\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0186\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0182\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0180\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0180\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0179\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0174\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0178\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0172\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0173\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0171\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0169\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0166\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[[ 3.5088509e-01  3.8217414e-02 -1.8055007e-02 ... -2.7565460e-04\n",
      "   1.1998541e-03  2.6011965e-04]\n",
      " [ 1.5077278e-01  4.4207174e-02 -3.4858737e-02 ... -2.9564823e-04\n",
      "   4.8746885e-04  8.1494596e-04]\n",
      " [ 1.9884324e-01  2.1659113e-02 -4.3723810e-02 ...  6.7886309e-04\n",
      "   2.1580630e-03  5.0903077e-04]\n",
      " ...\n",
      " [ 1.5835983e-01  3.4972476e-03 -9.3075400e-03 ...  1.9672967e-03\n",
      "   1.9422458e-03 -4.5024799e-04]\n",
      " [ 3.7906283e-01  2.8896290e-01  2.0872717e-01 ...  4.3463088e-03\n",
      "   6.9278013e-04 -2.5881138e-03]\n",
      " [ 9.3100667e-02 -2.7944641e-03 -1.2261948e-02 ...  4.8841152e-04\n",
      "   9.1659807e-04  5.9720676e-04]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_36 (Dense)            (None, 400)               673200    \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 400)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 200)               80200     \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 1682)              338082    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,091,482\n",
      "Trainable params: 1,091,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 1s 7ms/step - loss: 0.0294\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0246\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0234\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0225\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0218\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0213\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0209\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0204\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0200\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0201\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0197\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0193\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0190\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0188\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0186\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0181\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0180\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0178\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0176\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0171\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0170\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0175\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0174\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0173\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0169\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0167\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0164\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0163\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0158\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0158\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "[[ 5.4450965e-01  2.7074549e-01  2.2977330e-01 ...  5.0296206e-03\n",
      "  -2.2994294e-03 -4.4715009e-04]\n",
      " [ 1.9451848e-01  3.3133663e-04  8.1154853e-03 ... -7.7767042e-04\n",
      "   2.0553193e-03 -2.3584515e-03]\n",
      " [ 3.2873714e-01  1.2604436e-01  6.3102946e-02 ... -1.6254230e-03\n",
      "  -3.1272421e-04  2.9990962e-03]\n",
      " ...\n",
      " [ 5.0531842e-02 -3.2731574e-03 -1.8769890e-02 ...  1.3535362e-03\n",
      "   5.4127029e-03 -8.2100835e-03]\n",
      " [ 3.0605981e-01  6.2905580e-02  1.9660572e-02 ... -8.6095801e-04\n",
      "  -1.6910150e-03  1.8707641e-03]\n",
      " [ 4.6465027e-01  2.1690904e-01  2.7508935e-01 ...  3.1988437e-03\n",
      "   1.0845659e-05 -1.9825029e-03]]\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_39 (Dense)            (None, 400)               673200    \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 400)               0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 200)               80200     \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1682)              338082    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,091,482\n",
      "Trainable params: 1,091,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 1s 7ms/step - loss: 0.0311\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0259\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0246\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0235\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0228\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0223\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0218\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0212\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0209\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0205\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0202\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0201\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0201\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0199\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0193\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0190\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0188\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0187\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0187\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0184\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0179\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0178\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0178\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0176\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0172\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0176\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0171\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0172\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0168\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0166\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[[ 4.12742287e-01  1.04705513e-01  3.95722091e-02 ... -6.20229985e-04\n",
      "   5.71456563e-04  9.88027081e-04]\n",
      " [ 3.14751655e-01  6.52064756e-02  5.33167049e-02 ... -1.06462234e-04\n",
      "   1.03618111e-03  4.07300598e-04]\n",
      " [ 3.75774443e-01  7.83508569e-02  1.47455707e-01 ...  1.97458151e-03\n",
      "   3.07877245e-03 -1.72540604e-06]\n",
      " ...\n",
      " [ 4.07588810e-01 -2.32244506e-02  1.43479593e-02 ... -2.03156914e-03\n",
      "  -1.04087219e-03 -1.02201593e-05]\n",
      " [ 2.79817849e-01  9.17245746e-02  3.37436888e-03 ...  2.52565776e-04\n",
      "  -7.85326876e-04  7.48345279e-04]\n",
      " [ 1.56760454e-01  1.78295113e-02  2.61238478e-02 ... -5.46586816e-05\n",
      "  -1.81992375e-03  7.38652452e-05]]\n",
      "Model: \"sequential_14\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_42 (Dense)            (None, 400)               673200    \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 400)               0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 200)               80200     \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1682)              338082    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,091,482\n",
      "Trainable params: 1,091,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 1s 6ms/step - loss: 0.0314\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0262\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0248\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0238\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0232\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0226\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0223\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0216\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0214\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0209\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0205\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0204\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0198\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0197\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0195\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0193\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0195\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0195\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0190\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0187\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0183\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0179\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0179\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0176\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0177\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0175\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0173\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0171\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0174\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0174\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "[[ 4.0712178e-01  3.9579038e-02  4.0671952e-02 ...  6.4073899e-04\n",
      "  -2.9317341e-03  1.3946980e-04]\n",
      " [ 6.0374993e-01  2.1493995e-01  1.8415667e-01 ... -8.1305427e-04\n",
      "  -2.2048440e-03 -3.0705158e-03]\n",
      " [ 1.6927594e-01  9.0418402e-03  1.2858757e-02 ... -2.0219114e-04\n",
      "  -7.3911424e-04  1.3485347e-03]\n",
      " ...\n",
      " [-1.6178071e-02  4.9844757e-04 -2.1720018e-02 ... -2.8963655e-04\n",
      "  -4.4761342e-04 -2.3414118e-03]\n",
      " [ 2.2518277e-01 -7.5590424e-03 -7.3057367e-03 ...  1.4917315e-03\n",
      "  -2.4855365e-03  7.4585178e-04]\n",
      " [ 3.0632669e-01  2.8399279e-02  4.5810910e-03 ...  3.1082399e-04\n",
      "  -8.9860335e-04  1.2250233e-04]]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(train_data):\n",
    "    # Split the data into train and test sets for the current fold\n",
    "    train_ratings, test_ratings = user_item[train_index], user_item[test_index]\n",
    "\n",
    "    # Data preprocessing (do normalized)\n",
    "    normalized_Train_data = train_ratings / np.max(train_ratings)\n",
    "    normalized_Test_data = test_ratings / np.max(test_ratings)\n",
    "    \n",
    "    # Define and compile your model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(400, activation='relu', input_dim=user_item.shape[1]))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(user_item.shape[1], activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(normalized_Train_data, normalized_Train_data, epochs=30, batch_size=16, verbose=1)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    predicted_ratings = model.predict(normalized_Test_data)\n",
    "    print(predicted_ratings)\n",
    "\n",
    "    # Calculate evaluation metrics (RMSE and MAE)\n",
    "    true_ratings = test_ratings.flatten()\n",
    "    predicted_ratings = predicted_ratings.flatten()\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(true_ratings, predicted_ratings))\n",
    "    mae = np.mean(np.abs(true_ratings - predicted_ratings))\n",
    "\n",
    "    # Append the evaluation scores to the lists\n",
    "    rmse_scores.append(rmse)\n",
    "    mae_scores.append(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "448d3a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_105 (Dense)           (None, 16)                26928     \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 1682)              15138     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,202\n",
      "Trainable params: 42,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0340\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0297\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0274\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0264\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0264\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0255\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0249\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0253\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0248\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0248\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0249\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0245\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0244\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0244\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0245\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0244\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0240\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0245\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0243\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0243\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0241\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0244\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0239\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0239\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0241\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0240\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0237\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0240\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0240\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0240\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[[ 5.4801750e-01  2.5267461e-01  2.0046577e-01 ... -2.2565495e-04\n",
      "  -1.3876880e-04  2.3025103e-04]\n",
      " [ 3.0680889e-01  2.3875199e-03  3.7702605e-02 ... -1.9545859e-04\n",
      "   4.4941771e-05  2.3199222e-04]\n",
      " [ 1.0829742e-01 -1.6165823e-03 -7.7566504e-03 ... -1.6695660e-04\n",
      "   9.2458125e-05  8.6910685e-04]\n",
      " ...\n",
      " [ 1.2225485e-01  1.3816543e-03 -5.9043877e-03 ... -1.7463567e-04\n",
      "   7.5235541e-05  8.2874531e-04]\n",
      " [ 3.6765563e-01  1.7117677e-02  5.1762454e-02 ... -2.1218177e-04\n",
      "  -2.5175286e-05  3.7781254e-05]\n",
      " [ 5.5325568e-01  1.6329870e-01  6.2046334e-02 ... -6.3586136e-04\n",
      "  -2.0466364e-04  1.6680787e-03]]\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_108 (Dense)           (None, 16)                26928     \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 1682)              15138     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,202\n",
      "Trainable params: 42,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0335\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0289\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0267\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0261\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0258\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0255\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0252\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0249\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0249\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0248\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0243\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0244\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0242\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0243\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0242\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0246\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0241\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0243\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0241\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0240\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0242\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0240\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0239\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0239\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0235\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0239\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0239\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0238\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0241\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0241\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[[ 3.83749694e-01  1.46713018e-01  5.21777458e-02 ... -2.67063471e-13\n",
      "   3.61432431e-15  2.13588709e-14]\n",
      " [ 2.74918020e-01  4.64551300e-02  1.76389012e-02 ...  8.31248048e-14\n",
      "   1.12680564e-14  2.38923875e-15]\n",
      " [ 3.04336518e-01  3.77114713e-02  1.94560625e-02 ...  9.60478103e-15\n",
      "  -6.19298314e-15 -3.57723952e-15]\n",
      " ...\n",
      " [ 2.32079878e-01  1.51074696e-02  8.49182811e-03 ...  2.88912476e-13\n",
      "   2.18592166e-14  2.73744404e-15]\n",
      " [ 6.66609764e-01  3.68329495e-01  1.73976123e-01 ... -9.47281750e-13\n",
      "   1.86275691e-14  8.16495241e-14]\n",
      " [ 2.19566792e-01  1.24097792e-02  7.44113419e-03 ...  3.67372121e-13\n",
      "   2.90380513e-14  3.14967444e-15]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_111 (Dense)           (None, 16)                26928     \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 1682)              15138     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,202\n",
      "Trainable params: 42,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0318\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0275\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0258\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0252\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0247\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0247\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0244\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0243\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0242\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0240\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0242\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0238\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0238\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0237\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0237\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0237\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0236\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0234\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0235\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0237\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0234\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0236\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0234\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0233\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0234\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0233\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0232\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0232\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0232\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0232\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[[ 7.2649342e-01  3.3564088e-01  2.2587748e-01 ... -2.7469335e-07\n",
      "   1.3874834e-12  5.7898898e-05]\n",
      " [ 2.5743115e-01  5.5333148e-03  1.2425139e-02 ...  8.6065718e-08\n",
      "   9.5906681e-13  4.1164368e-04]\n",
      " [ 3.8170451e-01  5.8154646e-02  4.1821681e-02 ...  3.8675833e-07\n",
      "   3.5837451e-12 -1.6142064e-04]\n",
      " ...\n",
      " [ 2.5743115e-01  5.5333148e-03  1.2425139e-02 ...  8.6065718e-08\n",
      "   9.5906681e-13  4.1164368e-04]\n",
      " [ 3.8937750e-01  7.4658453e-02  3.4415003e-02 ...  4.9112379e-07\n",
      "   1.6473014e-12  7.7960722e-06]\n",
      " [ 4.8964456e-01  1.7838478e-01  1.1952641e-01 ... -9.5429975e-08\n",
      "   8.3729876e-13  6.6215463e-04]]\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_114 (Dense)           (None, 16)                26928     \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_67 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 1682)              15138     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,202\n",
      "Trainable params: 42,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0339\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0287\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0269\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0263\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0259\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0257\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0255\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0252\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0249\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0247\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0245\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0246\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0244\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0244\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0244\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0244\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0244\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0244\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0246\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0245\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0242\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0239\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0241\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0242\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0239\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0242\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0238\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0241\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0241\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0239\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "[[ 3.94492030e-01  7.27888569e-02  5.10715060e-02 ...  1.12873728e-08\n",
      "   8.52145877e-06 -3.35391590e-08]\n",
      " [ 4.70816731e-01  1.59817830e-01  1.06662393e-01 ... -1.78080199e-08\n",
      "   4.24604423e-06 -2.86206365e-08]\n",
      " [ 4.06291366e-01  1.47452518e-01  8.36731493e-02 ... -1.85699633e-08\n",
      "  -5.28933697e-08 -2.57553587e-08]\n",
      " ...\n",
      " [ 2.80300319e-01  2.58828364e-02  2.26155408e-02 ... -7.62246088e-09\n",
      "   2.64054688e-06 -7.44697237e-09]\n",
      " [ 3.36786270e-01  7.85924569e-02  4.41557691e-02 ... -2.09908286e-08\n",
      "  -2.49702339e-07 -1.34463365e-08]\n",
      " [ 2.73398191e-01  4.67500165e-02  2.10390333e-02 ... -1.43955941e-08\n",
      "   8.42699023e-07 -1.08804761e-08]]\n",
      "Model: \"sequential_39\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_117 (Dense)           (None, 16)                26928     \n",
      "                                                                 \n",
      " dropout_68 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_69 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 1682)              15138     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,202\n",
      "Trainable params: 42,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0344\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0294\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0275\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0267\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0264\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0262\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0259\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0259\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0255\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0257\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0253\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0255\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0250\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0249\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0253\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0252\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0253\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0251\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0248\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0248\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0250\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0247\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0247\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0250\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0247\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0248\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0246\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0248\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0244\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0248\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[[ 3.2844290e-01  5.4039780e-02  4.2286120e-02 ...  8.9679641e-05\n",
      "   1.1018919e-05  1.0533300e-07]\n",
      " [ 5.0140691e-01  2.3047778e-01  1.4199914e-01 ...  2.1430735e-04\n",
      "   1.3566023e-05  7.0353977e-08]\n",
      " [ 3.1343558e-01  4.8643496e-02  3.3324771e-02 ...  9.6962205e-05\n",
      "   7.0198193e-06  1.1608293e-08]\n",
      " ...\n",
      " [ 5.8638379e-02 -3.1493045e-03  1.8845974e-03 ...  4.6844365e-05\n",
      "  -5.1104330e-06 -9.4510668e-08]\n",
      " [ 2.3268563e-01  4.3133087e-02  1.6435722e-02 ...  6.1385457e-05\n",
      "   2.5286020e-06 -1.0322800e-08]\n",
      " [ 3.6853218e-01  1.9584000e-02  4.5284554e-02 ...  6.1902028e-05\n",
      "   1.7541570e-05  2.1435704e-07]]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(train_data):\n",
    "    # Split the data into train and test sets for the current fold\n",
    "    train_ratings, test_ratings = user_item[train_index], user_item[test_index]\n",
    "\n",
    "    # Data preprocessing (do normalized)\n",
    "    normalized_Train_data = train_ratings / np.max(train_ratings)\n",
    "    normalized_Test_data = test_ratings / np.max(test_ratings)\n",
    "    \n",
    "    # Define and compile your model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, activation='relu', input_dim=user_item.shape[1]))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(user_item.shape[1], activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(normalized_Train_data, normalized_Train_data, epochs=30, batch_size=16, verbose=1)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    predicted_ratings = model.predict(normalized_Test_data)\n",
    "    print(predicted_ratings)\n",
    "\n",
    "    # Calculate evaluation metrics (RMSE and MAE)\n",
    "    true_ratings = test_ratings.flatten()\n",
    "    predicted_ratings = predicted_ratings.flatten()\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(true_ratings, predicted_ratings))\n",
    "    mae = np.mean(np.abs(true_ratings - predicted_ratings))\n",
    "\n",
    "    # Append the evaluation scores to the lists\n",
    "    rmse_scores.append(rmse)\n",
    "    mae_scores.append(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d36763c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE: 0.8848075568105578\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print the average evaluation scores\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "# avg_mae = np.mean(mae_scores)\n",
    "print(\"Average RMSE:\", avg_rmse)\n",
    "# print(\"Average MAE:\", avg_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "910b9379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 7.4782300e-01,  4.5401178e-02, -7.9210941e-03, ...,\n",
       "        -1.0471557e-02,  1.4117311e-02,  7.8749312e-03],\n",
       "       [-4.6319932e-01, -8.4114015e-02, -4.9162246e-02, ...,\n",
       "        -3.7840093e-03,  1.5474216e-05, -6.4573600e-03],\n",
       "       [ 7.6942241e-01,  1.2825084e-01,  1.9776590e-01, ...,\n",
       "         1.3136594e-04, -5.7781804e-03, -1.1077246e-02],\n",
       "       ...,\n",
       "       [ 1.2242266e+00, -1.3858713e-01,  1.4246212e-01, ...,\n",
       "        -9.8262320e-04,  2.0492013e-04, -4.7205738e-03],\n",
       "       [ 3.0577534e-01, -1.6062733e-02,  8.8236146e-03, ...,\n",
       "        -7.9621896e-05, -1.3419022e-04, -4.6160645e-03],\n",
       "       [ 1.5414940e+00, -1.5390078e-03, -7.7480182e-02, ...,\n",
       "        -4.2775874e-03,  7.1041249e-03,  1.4999604e-02]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings = model.predict(test_data)\n",
    "predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa5214b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1682\n",
      "1682\n"
     ]
    }
   ],
   "source": [
    "print(len(predicted_ratings[0]))\n",
    "print( len(test_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d8cd94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 7.4782300e-01,  4.5401178e-02, -7.9210941e-03, ...,\n",
       "        -1.0471557e-02,  1.4117311e-02,  7.8749312e-03],\n",
       "       [-4.6319932e-01, -8.4114015e-02, -4.9162246e-02, ...,\n",
       "        -3.7840093e-03,  1.5474216e-05, -6.4573600e-03],\n",
       "       [ 7.6942241e-01,  1.2825084e-01,  1.9776590e-01, ...,\n",
       "         1.3136594e-04, -5.7781804e-03, -1.1077246e-02],\n",
       "       ...,\n",
       "       [ 1.2242266e+00, -1.3858713e-01,  1.4246212e-01, ...,\n",
       "        -9.8262320e-04,  2.0492013e-04, -4.7205738e-03],\n",
       "       [ 3.0577534e-01, -1.6062733e-02,  8.8236146e-03, ...,\n",
       "        -7.9621896e-05, -1.3419022e-04, -4.6160645e-03],\n",
       "       [ 1.5414940e+00, -1.5390078e-03, -7.7480182e-02, ...,\n",
       "        -4.2775874e-03,  7.1041249e-03,  1.4999604e-02]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A=[]\n",
    "# A=predicted_ratings[1]\n",
    "print(type(predicted_ratings))\n",
    "predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "145ca66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG@10: 0.6411\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "k = 10  # Top k 推薦項目數量\n",
    "\n",
    "ndcg_scores = []\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    true_labels = test_data[i]\n",
    "    predicted_labels = predicted_ratings[i]\n",
    "\n",
    "    # 按照預測評分降續排序，提取前k個項目的真實評分\n",
    "    top_k_indices = np.argsort(predicted_labels)[::-1][:k]\n",
    "    true_ratings_k = true_labels[top_k_indices]\n",
    "\n",
    "    # 計算累積增益\n",
    "    cumulative_gain = (2 ** true_ratings_k - 1) / np.log2(np.arange(2, k + 2))\n",
    "\n",
    "    # 按照真實評分降續排序，提取前k個項目的真實評分\n",
    "    ideal_true_ratings_k = np.sort(true_labels)[::-1][:k]\n",
    "\n",
    "    # 計算理想累積增益\n",
    "    ideal_cumulative_gain = (2 ** ideal_true_ratings_k - 1) / np.log2(np.arange(2, k + 2))\n",
    "\n",
    "    # 計算NDCG@k\n",
    "    ndcg_at_k = np.sum(cumulative_gain) / np.sum(ideal_cumulative_gain)\n",
    "\n",
    "    ndcg_scores.append(ndcg_at_k)\n",
    "\n",
    "# 計算平均NDCG@k\n",
    "average_ndcg_at_k = np.mean(ndcg_scores)\n",
    "\n",
    "print(\"Average NDCG@{}: {:.4f}\".format(k, average_ndcg_at_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fbd895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7615ad10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall@10: 0.1632\n"
     ]
    }
   ],
   "source": [
    "min_rating = 0\n",
    "max_rating = 5\n",
    "k = 10  # Top k 推薦項目數量\n",
    "threshold = 0.5  \n",
    "\n",
    "recall_scores = []\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    true_ratings = test_data[i]\n",
    "    predicted_values = predicted_ratings[i] * (max_rating - min_rating) + min_rating\n",
    "\n",
    "    # 預測預測評分中前k個最高評分的項目索引\n",
    "    top_k_indices = predicted_values.argsort()[-k:][::-1]\n",
    "#     print(\"預測的movies:\")\n",
    "#     print(top_k_indices)\n",
    "\n",
    "    # 計算真實評分中大於等於threshold的項目數量\n",
    "    relevant_items = np.sum(true_ratings >= threshold)\n",
    "\n",
    "    # 計算推薦項目中真實評分大於等於threshold的項目數量\n",
    "    recommended_relevant_items = np.sum(true_ratings[top_k_indices] >= threshold)\n",
    "\n",
    "    # 計算 Recall@k\n",
    "    recall_at_k = recommended_relevant_items / relevant_items\n",
    "\n",
    "    recall_scores.append(recall_at_k)\n",
    "\n",
    "# 計算平均 Recall@k\n",
    "average_recall_at_k = np.mean(recall_scores)\n",
    "\n",
    "print(\"Average Recall@{}: {:.4f}\".format(k, average_recall_at_k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1a7336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9550dc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8f496a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
