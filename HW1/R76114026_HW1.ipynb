{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6735349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "from torch_geometric.nn import GCNConv\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch.nn import Linear, Parameter\n",
    "from torch.nn import ReLU, Sequential\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca4c550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取文本檔 nodes&edges\n",
    "with open('./Synthetic/5000/0.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# 解析邊界資訊\n",
    "edges = []\n",
    "for line in lines:\n",
    "    source_node_index, target_node_index = map(int, line.strip().split())\n",
    "    edges.append([source_node_index, target_node_index])  \n",
    "    \n",
    "# print(edges)\n",
    "    \n",
    "# 計算節點數和邊數\n",
    "num_nodes = max([max(e) for e in edges]) + 1\n",
    "num_edges = len(edges)\n",
    "dvnodes = (2*num_edges) / num_nodes\n",
    "# print(dvnodes)\n",
    "\n",
    "# 建立邊界矩陣(edge_index)\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "# x = torch.tensor(dvnodes, dtype=torch.long)\n",
    "# x = torch.randn(num_nodes)\n",
    "# print(x)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "314242e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi-Chen\\AppData\\Local\\Temp/ipykernel_15172/490777784.py:21: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  y = torch.tensor(y, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "# 讀取文本檔 exact BC value，然後把它當成data.x的資料\n",
    "with open('./Synthetic/5000/0_score.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# 解析節點資訊\n",
    "features = []\n",
    "y=[]\n",
    "\n",
    "for line in lines:\n",
    "    source_node_index, target_node_index = map(float, line.strip().split())\n",
    "    features.append([dvnodes,1,1]) \n",
    "    y.append(target_node_index)\n",
    "#     y.append([0])\n",
    "    #這裡代表每一節點的node feature，作者把[dv, 1, 1]當成initial node features\n",
    "    #在這裡我把它設定成[取得的exact BC valu, 1, 1]做為每一節點的node features\n",
    "    \n",
    "# print(features)\n",
    "    \n",
    "# 建立節點特徵矩陣\n",
    "x = torch.tensor(features, dtype=torch.float)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "print(y)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96406547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[5000, 3], edge_index=[2, 19982], y=[5000])\n"
     ]
    }
   ],
   "source": [
    "# 建立 Data 物件\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "# 顯示 Data 物件中的資訊\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ed772b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes: 5000\n",
      "edges: 19982\n",
      "Average node degree: 7.99\n",
      "edge_index: tensor([[   0,    0,    0,  ..., 4844, 4870, 4937],\n",
      "        [   4,    5,    8,  ..., 4849, 4928, 4953]])\n",
      "data.x:  tensor([[7.9928, 1.0000, 1.0000],\n",
      "        [7.9928, 1.0000, 1.0000],\n",
      "        [7.9928, 1.0000, 1.0000],\n",
      "        ...,\n",
      "        [7.9928, 1.0000, 1.0000],\n",
      "        [7.9928, 1.0000, 1.0000],\n",
      "        [7.9928, 1.0000, 1.0000]])\n",
      "data.y:  tensor([0, 0, 0,  ..., 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "#dataset information\n",
    "print('nodes:',data.num_nodes)\n",
    "print('edges:',data.num_edges)\n",
    "print(f'Average node degree: {(2*data.num_edges) / data.num_nodes:.2f}')\n",
    "print('edge_index:',data.edge_index)\n",
    "print('data.x: ',data.x)\n",
    "print('data.y: ',data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd680c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 劃分數據集\n",
    "num_nodes = data.num_nodes # 總節點數\n",
    "perm = torch.randperm(num_nodes)\n",
    "\n",
    "train_mask = perm < num_nodes * 0.6  # 60% 用來訓練\n",
    "val_mask = (perm >= num_nodes * 0.6) & (perm < num_nodes * 0.8)  # 20% for valid\n",
    "test_mask = perm >= num_nodes * 0.8  # 20% for test\n",
    "# print(type(train_mask))\n",
    "data.train_mask = train_mask\n",
    "data.val_mask = val_mask\n",
    "data.test_mask = test_mask\n",
    "\n",
    "# train_index = [1, 3, 5, 7, 9] # 訓練節點的索引\n",
    "# n_nodes = 10 # 總節點數\n",
    "\n",
    "# train_mask = np.zeros(n_nodes, dtype=bool)\n",
    "# train_mask[train_index] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44bfbdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False,  ...,  True, False,  True])\n"
     ]
    }
   ],
   "source": [
    "print(data.train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57d55f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ True, False,  True,  ..., False,  True, False])\n"
     ]
    }
   ],
   "source": [
    "print(data.val_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6dcc798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False,  True, False,  ..., False, False, False])\n"
     ]
    }
   ],
   "source": [
    "print(data.test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94c5721c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,    0,  ..., 4844, 4870, 4937],\n",
      "        [   4,    5,    8,  ..., 4849, 4928, 4953]])\n"
     ]
    }
   ],
   "source": [
    "print(data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1076c345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    4],\n",
      "        [   0,    5],\n",
      "        [   0,    8],\n",
      "        ...,\n",
      "        [4844, 4849],\n",
      "        [4870, 4928],\n",
      "        [4937, 4953]])\n"
     ]
    }
   ],
   "source": [
    "print(edge_index.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fda08e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b59ad41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.9928, 1.0000, 1.0000],\n",
       "        [7.9928, 1.0000, 1.0000],\n",
       "        [7.9928, 1.0000, 1.0000],\n",
       "        ...,\n",
       "        [7.9928, 1.0000, 1.0000],\n",
       "        [7.9928, 1.0000, 1.0000],\n",
       "        [7.9928, 1.0000, 1.0000]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bd3e331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters setting\n",
    "learning_rate = 0.0001\n",
    "embedding_dimension = 128\n",
    "mini_batch_size = 16\n",
    "average_node_samping_times = 5\n",
    "maximum_episodes = 10000\n",
    "layer_iterations = 5\n",
    "aux_ori_feature = 128\n",
    "aux_feat_dim = 4 \n",
    "final_feature = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4d08e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立GCN模型 產生embedding\n",
    "class GCNMaxPooling(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='max') #使用 Max pooling layer aggregator. \n",
    "        self.lin = Linear(in_channels, out_channels)\n",
    "        self.bias = torch.nn.Parameter(torch.zeros(out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Linearly transform node feature matrix.\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Normalize node features.\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "        norm = norm.view(-1, 1)\n",
    "\n",
    "        # Propagate the messages.\n",
    "        out = self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "        # Add bias and apply activation function.\n",
    "        out = out + self.bias\n",
    "        out = torch.nn.functional.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # Normalize node features.\n",
    "        return norm * x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # Max pooling layer aggregator.\n",
    "        print('aggr_out:',aggr_out)\n",
    "        return aggr_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fcaea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=GCNMaxPooling(data.num_features, embedding_dimension)\n",
    "#(每個node特徵維度, 想輸出的embedding dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7d7539b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggr_out: tensor([[-4.2260, -0.2578, -0.5104,  ...,  3.0376, -3.0985, -4.3057],\n",
      "        [-4.2260, -0.2578, -0.5104,  ...,  3.0376, -3.0985, -4.3057],\n",
      "        [-4.2260, -0.2578, -0.5104,  ...,  3.0376, -3.0985, -4.3057],\n",
      "        ...,\n",
      "        [-0.8452, -0.0516, -0.1021,  ...,  0.6075, -0.6197, -0.8611],\n",
      "        [-0.8452, -0.0516, -0.1021,  ...,  0.6075, -0.6197, -0.8611],\n",
      "        [-0.8452, -0.0516, -0.1021,  ...,  0.6075, -0.6197, -0.8611]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "encoder GCN model output tensor([[0.0000, 0.0000, 0.0000,  ..., 3.0376, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 3.0376, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 3.0376, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.6075, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.6075, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.6075, 0.0000, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Embedding shape: [5000, 128]\n"
     ]
    }
   ],
   "source": [
    "h = model(data.x, data.edge_index)\n",
    "print('encoder GCN model output',h)\n",
    "print(f'Embedding shape: {list(h.shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "534ddf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 3.0376, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 3.0376, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 3.0376, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.6075, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.6075, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.6075, 0.0000, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(h) #顯示產生出來的embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "552cbd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立two layer MLP當成decoder\n",
    "class TwoLayerMLP(torch.nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        super(TwoLayerMLP, self).__init__()\n",
    "        self.linear1 = Linear(in_features, hidden_features)\n",
    "        self.activation = ReLU()\n",
    "        self.linear2 = Linear(hidden_features, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.activation(out)\n",
    "        out = self.linear2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00ad503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltwo = TwoLayerMLP(aux_ori_feature,aux_feat_dim,final_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "790f748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = modeltwo(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9513f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#用來看產生出來的ranking score\n",
    "# x=4500\n",
    "# print(h2[4900])\n",
    "# for x in range(5000):\n",
    "#     print(h2[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12e0eecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    " print(data.y)\n",
    "print(type(data.y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf954272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, modeltwo, data, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data.x, data.edge_index)\n",
    "#     print(output)\n",
    "    finaloutput = modeltwo(output)\n",
    "    print(finaloutput)\n",
    "\n",
    "#     Finalll=finaloutput.tolist()\n",
    "#     print(type(Finalll))\n",
    "\n",
    "#     print('OUT TRAIN MASK',finaloutput[data.train_mask])\n",
    "#     print('******************')\n",
    "#     print('Y TRAIN MASK',data.y[data.train_mask])\n",
    "#     data.y[data.train_mask] = data.y[data.train_mask].squeeze(1)\n",
    "    loss = criterion(finaloutput[data.train_mask], data.y[data.train_mask])\n",
    "#     loss = F.nll_loss(finaloutput[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7215072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, modeltwo, data):\n",
    "    model.eval()\n",
    "    output = model(data.x, data.edge_index)\n",
    "    finaloutput = modeltwo(output)\n",
    "    pred = finaloutput.argmax(dim=1)\n",
    "    correct = pred.eq(data.y)\n",
    "    accuracy = torch.sum(correct[data.test_mask]).item() / data.test_mask.sum().item()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "661092ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "tensor([[-0.7383],\n",
      "        [-0.7383],\n",
      "        [-0.7383],\n",
      "        ...,\n",
      "        [-0.3761],\n",
      "        [-0.3761],\n",
      "        [-0.3761]], grad_fn=<AddmmBackward0>)\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "Epoch: 1, Loss: 0.0000, Accuracy: 1.0000\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "tensor([[-0.7383],\n",
      "        [-0.7383],\n",
      "        [-0.7383],\n",
      "        ...,\n",
      "        [-0.3761],\n",
      "        [-0.3761],\n",
      "        [-0.3761]], grad_fn=<AddmmBackward0>)\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "Epoch: 2, Loss: 0.0000, Accuracy: 1.0000\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "tensor([[-0.7383],\n",
      "        [-0.7383],\n",
      "        [-0.7383],\n",
      "        ...,\n",
      "        [-0.3761],\n",
      "        [-0.3761],\n",
      "        [-0.3761]], grad_fn=<AddmmBackward0>)\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "Epoch: 3, Loss: 0.0000, Accuracy: 1.0000\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "tensor([[-0.7383],\n",
      "        [-0.7383],\n",
      "        [-0.7383],\n",
      "        ...,\n",
      "        [-0.3761],\n",
      "        [-0.3761],\n",
      "        [-0.3761]], grad_fn=<AddmmBackward0>)\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "Epoch: 4, Loss: 0.0000, Accuracy: 1.0000\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "tensor([[-0.7383],\n",
      "        [-0.7383],\n",
      "        [-0.7383],\n",
      "        ...,\n",
      "        [-0.3761],\n",
      "        [-0.3761],\n",
      "        [-0.3761]], grad_fn=<AddmmBackward0>)\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "Epoch: 5, Loss: 0.0000, Accuracy: 1.0000\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "tensor([[-0.7383],\n",
      "        [-0.7383],\n",
      "        [-0.7383],\n",
      "        ...,\n",
      "        [-0.3761],\n",
      "        [-0.3761],\n",
      "        [-0.3761]], grad_fn=<AddmmBackward0>)\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "Epoch: 6, Loss: 0.0000, Accuracy: 1.0000\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "tensor([[-0.7383],\n",
      "        [-0.7383],\n",
      "        [-0.7383],\n",
      "        ...,\n",
      "        [-0.3761],\n",
      "        [-0.3761],\n",
      "        [-0.3761]], grad_fn=<AddmmBackward0>)\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "Epoch: 7, Loss: 0.0000, Accuracy: 1.0000\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "tensor([[-0.7383],\n",
      "        [-0.7383],\n",
      "        [-0.7383],\n",
      "        ...,\n",
      "        [-0.3761],\n",
      "        [-0.3761],\n",
      "        [-0.3761]], grad_fn=<AddmmBackward0>)\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "Epoch: 8, Loss: 0.0000, Accuracy: 1.0000\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "tensor([[-0.7383],\n",
      "        [-0.7383],\n",
      "        [-0.7383],\n",
      "        ...,\n",
      "        [-0.3761],\n",
      "        [-0.3761],\n",
      "        [-0.3761]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "Epoch: 9, Loss: 0.0000, Accuracy: 1.0000\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "tensor([[-0.7383],\n",
      "        [-0.7383],\n",
      "        [-0.7383],\n",
      "        ...,\n",
      "        [-0.3761],\n",
      "        [-0.3761],\n",
      "        [-0.3761]], grad_fn=<AddmmBackward0>)\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "Epoch: 10, Loss: 0.0000, Accuracy: 1.0000\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "tensor([[-0.7383],\n",
      "        [-0.7383],\n",
      "        [-0.7383],\n",
      "        ...,\n",
      "        [-0.3761],\n",
      "        [-0.3761],\n",
      "        [-0.3761]], grad_fn=<AddmmBackward0>)\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "Epoch: 11, Loss: 0.0000, Accuracy: 1.0000\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "tensor([[-0.7383],\n",
      "        [-0.7383],\n",
      "        [-0.7383],\n",
      "        ...,\n",
      "        [-0.3761],\n",
      "        [-0.3761],\n",
      "        [-0.3761]], grad_fn=<AddmmBackward0>)\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "Epoch: 12, Loss: 0.0000, Accuracy: 1.0000\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "tensor([[-0.7383],\n",
      "        [-0.7383],\n",
      "        [-0.7383],\n",
      "        ...,\n",
      "        [-0.3761],\n",
      "        [-0.3761],\n",
      "        [-0.3761]], grad_fn=<AddmmBackward0>)\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "Epoch: 13, Loss: 0.0000, Accuracy: 1.0000\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "tensor([[-0.7383],\n",
      "        [-0.7383],\n",
      "        [-0.7383],\n",
      "        ...,\n",
      "        [-0.3761],\n",
      "        [-0.3761],\n",
      "        [-0.3761]], grad_fn=<AddmmBackward0>)\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "Epoch: 14, Loss: 0.0000, Accuracy: 1.0000\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "tensor([[-0.7383],\n",
      "        [-0.7383],\n",
      "        [-0.7383],\n",
      "        ...,\n",
      "        [-0.3761],\n",
      "        [-0.3761],\n",
      "        [-0.3761]], grad_fn=<AddmmBackward0>)\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "Epoch: 15, Loss: 0.0000, Accuracy: 1.0000\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "tensor([[-0.7383],\n",
      "        [-0.7383],\n",
      "        [-0.7383],\n",
      "        ...,\n",
      "        [-0.3761],\n",
      "        [-0.3761],\n",
      "        [-0.3761]], grad_fn=<AddmmBackward0>)\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "Epoch: 16, Loss: 0.0000, Accuracy: 1.0000\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "tensor([[-0.7383],\n",
      "        [-0.7383],\n",
      "        [-0.7383],\n",
      "        ...,\n",
      "        [-0.3761],\n",
      "        [-0.3761],\n",
      "        [-0.3761]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "Epoch: 17, Loss: 0.0000, Accuracy: 1.0000\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "tensor([[-0.7383],\n",
      "        [-0.7383],\n",
      "        [-0.7383],\n",
      "        ...,\n",
      "        [-0.3761],\n",
      "        [-0.3761],\n",
      "        [-0.3761]], grad_fn=<AddmmBackward0>)\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "Epoch: 18, Loss: 0.0000, Accuracy: 1.0000\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "tensor([[-0.7383],\n",
      "        [-0.7383],\n",
      "        [-0.7383],\n",
      "        ...,\n",
      "        [-0.3761],\n",
      "        [-0.3761],\n",
      "        [-0.3761]], grad_fn=<AddmmBackward0>)\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "Epoch: 19, Loss: 0.0000, Accuracy: 1.0000\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "tensor([[-0.7383],\n",
      "        [-0.7383],\n",
      "        [-0.7383],\n",
      "        ...,\n",
      "        [-0.3761],\n",
      "        [-0.3761],\n",
      "        [-0.3761]], grad_fn=<AddmmBackward0>)\n",
      "aggr_out: tensor([[ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        [ 1.3092, -1.2458,  4.7707,  ..., -2.3640,  1.5771, -2.6470],\n",
      "        ...,\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294],\n",
      "        [ 0.2618, -0.2492,  0.9541,  ..., -0.4728,  0.3154, -0.5294]],\n",
      "       grad_fn=<ScatterReduceBackward0>)\n",
      "Epoch: 20, Loss: 0.0000, Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "\n",
    "# model=GCNMaxPooling(data.num_features, embedding_dimension).to(dtype=torch.long, device=device)\n",
    "# modeltwo = TwoLayerMLP(aux_ori_feature,aux_feat_dim,final_feature).to(dtype=torch.long, device=device)\n",
    "\n",
    "# model = GCN(input_dim=data.num_features, hidden_dim=16, output_dim=dataset.num_classes)\n",
    "model=GCNMaxPooling(data.num_features, embedding_dimension).to(device=device)\n",
    "modeltwo = TwoLayerMLP(aux_ori_feature,aux_feat_dim,final_feature).to(device=device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "\n",
    "for epoch in range(20): #maximum_episodes = 10000\n",
    "    loss = train(model, modeltwo, data, optimizer)\n",
    "    acc = test(model, modeltwo, data)\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {loss:.4f}, Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "173d094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#下面是建立多個圖檔資料集的class設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecb07f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(MyDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['0.txt', '1.txt','2.txt','3.txt','4.txt','5.txt']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def download(self):\n",
    "        # 下載數據集，這邊因為已經有數據集了，所以pass\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        # 讀取txt檔，建立多個graph，然後把他們轉換成Data\n",
    "        data_list = []\n",
    "        for i, file in enumerate(self.raw_paths):\n",
    "            edge_index = []\n",
    "            node_features = []\n",
    "            label = []\n",
    "            \n",
    "            with open(file, 'r') as f:\n",
    "                for line in f:\n",
    "                    if line.startswith('node'):\n",
    "                        node_id, feature, label_ = line.strip().split('')\n",
    "                        node_features.append([float(x) for x in feature.split(',')])\n",
    "                        label.append(int(label_))\n",
    "                    else:\n",
    "                        src, dst = line.strip().split('\\t')\n",
    "                        edge_index.append([int(src), int(dst)])\n",
    "            edge_index = torch.tensor(edge_index).t().contiguous()\n",
    "            node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "            label = torch.tensor(label, dtype=torch.long)\n",
    "            data = Data(x=node_features, edge_index=edge_index, y=label)\n",
    "            data_list.append(data)\n",
    "        # 把Data列表轉換成PyTorch Geometric的Datalist\n",
    "        data, slices = self.collate(data_list)\n",
    "        # 保存DataList\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cad1e1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = MyDataset(root='./Synthetic/5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a580aee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[0], edge_index=[2, 19982], y=[0])\n",
      "Data(x=[0], edge_index=[2, 19981], y=[0])\n",
      "Data(x=[0], edge_index=[2, 19980], y=[0])\n",
      "Data(x=[0], edge_index=[2, 19982], y=[0])\n",
      "Data(x=[0], edge_index=[2, 19984], y=[0])\n",
      "Data(x=[0], edge_index=[2, 19981], y=[0])\n"
     ]
    }
   ],
   "source": [
    "print(model[0])\n",
    "print(model[1])\n",
    "print(model[2])\n",
    "print(model[3])\n",
    "print(model[4])\n",
    "print(model[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88ca902f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,    0,  ..., 4844, 4870, 4937],\n",
      "        [   4,    5,    8,  ..., 4849, 4928, 4953]])\n"
     ]
    }
   ],
   "source": [
    "print(model[0].edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7aaff861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac8364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c74dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
